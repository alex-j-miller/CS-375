{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10716,"sourceType":"modelInstanceVersion","modelInstanceId":8658}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ntorch.set_default_device(\"cuda\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n\ninputs = tokenizer('''def print_prime(n):\n   \"\"\"\n   Print all primes between 1 and n\n   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n\noutputs = model.generate(**inputs, max_length=200)\ntext = tokenizer.batch_decode(outputs)[0]\nprint(text)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-12T15:55:45.593655Z","iopub.execute_input":"2024-04-12T15:55:45.594004Z","iopub.status.idle":"2024-04-12T15:59:47.657747Z","shell.execute_reply.started":"2024-04-12T15:55:45.593975Z","shell.execute_reply":"2024-04-12T15:59:47.656760Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/863 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"975dd17d62d047cdb6899174fed55f64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi.py:   0%|          | 0.00/9.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5bfcf4b43134aa7a77648c29b47dc3e"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n- configuration_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi.py:   0%|          | 0.00/62.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b64ccf686f846988fc4f0514b0aaf40"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n- modeling_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c32c383040f498888b2d1b2108f9db2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d857882ad0784d378c10baeb6e822a14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40642ca4b4fa490eb362729beb5c9ae9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6534f0a0f1e74e36a690cc777b36cfa2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"526cce947147427e86bcedbfb522e3e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d73a8609f9493d8809dba89ad484ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"266dc57b49f9497ab29e420cb69bbd16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e09826bf7d9142f08d062134212e11ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a751da30f9e942f2b787172676cf9c6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8f4b6cf2b9845a798c833eca27cb07d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90cbfc1fb38043efa7d35c8c44ca355e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76afc1e157de4cf5adf9f0e3a1ba5e75"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"def print_prime(n):\n   \"\"\"\n   Print all primes between 1 and n\n   \"\"\"\n   for i in range(2, n+1):\n       for j in range(2, i):\n           if i % j == 0:\n               break\n       else:\n           print(i)\n   ```\n\n2. Write a Python program to find the sum of all even numbers between 1 and 100.\n\n   Ideas: Use a for loop to iterate over all numbers between 1 and 100. Use an if statement to check if the number is even. If it is, add it to a running total.\n\n   ```python\n   total = 0\n   for i in range(1, 101):\n       if i % 2 == 0:\n           total += i\n   print(total)\n   ```\n\n3. Write a Python program to find the largest number in a list.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('https://goo.gl/0OYkPK')\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Define the text you want to evaluate\n# text = \"Once upon a time, there was a bug.\"\ntext = df[\"storytitle\"][0]\n\n# Define additional context\nadditional_text = df['sentence1'][0] + df['sentence2'][0] + df['sentence3'][0] + df['sentence4'][0] + df['sentence5'][0]\n\n# Combine the input text and additional context\ntext_with_context = f\"{text} {additional_text}\"\n\n\n# Tokenize the text with context\ninputs = tokenizer(text_with_context, return_tensors=\"pt\", max_length=100, truncation=True)\n\n# Prepare the input tensor\ninput_ids = inputs.input_ids.to(device)\n\n# Prepare the target labels, ignoring the prompt\nprompt_len = len(tokenizer(text, return_tensors=\"pt\")[\"input_ids\"][0])\ntarget_ids = input_ids.clone()\ntarget_ids[:, :prompt_len] = -100\n\n# Compute the loss\nwith torch.no_grad():\n    outputs = model(input_ids, labels=target_ids)\n    neg_log_likelihood = outputs.loss\n\n# Compute perplexity\nperplexity = torch.exp(neg_log_likelihood)\n\nprint(f\"Loss: {neg_log_likelihood.item()}\")\nprint(f\"Perplexity: {perplexity.item()}\")\n\n\n\n# Debugging outputs\nprint(\"Input Text with Context:\", text_with_context)\nprint(\"Tokenized Input IDs:\", input_ids)\nprint(\"Target IDs:\", target_ids)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T16:01:23.206138Z","iopub.execute_input":"2024-04-12T16:01:23.207046Z","iopub.status.idle":"2024-04-12T16:01:29.804100Z","shell.execute_reply.started":"2024-04-12T16:01:23.207012Z","shell.execute_reply":"2024-04-12T16:01:29.803126Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Loss: 2.1900503635406494\nPerplexity: 8.935663223266602\nInput Text with Context: David Drops the Weight David noticed he had put on a lot of weight recently.He examined his habits to try and figure out the reason.He realized he'd been eating too much fast food lately.He stopped going to burger places and started a vegetarian diet.After a few weeks, he started to feel much better.\nTokenized Input IDs: tensor([[11006, 41692,   262, 14331,  3271,  6810,   339,   550,  1234,   319,\n           257,  1256,   286,  3463,  2904,    13,  1544, 11068,   465, 13870,\n           284,  1949,   290,  3785,   503,   262,  1738,    13,  1544,  6939,\n           339,  1549,   587,  6600,  1165,   881,  3049,  2057, 16537,    13,\n          1544,  5025,  1016,   284, 26593,  4113,   290,  2067,   257, 24053,\n          5496,    13,  3260,   257,  1178,  2745,    11,   339,  2067,   284,\n          1254,   881,  1365,    13]], device='cuda:0')\nTarget IDs: tensor([[ -100,  -100,  -100,  -100,  3271,  6810,   339,   550,  1234,   319,\n           257,  1256,   286,  3463,  2904,    13,  1544, 11068,   465, 13870,\n           284,  1949,   290,  3785,   503,   262,  1738,    13,  1544,  6939,\n           339,  1549,   587,  6600,  1165,   881,  3049,  2057, 16537,    13,\n          1544,  5025,  1016,   284, 26593,  4113,   290,  2067,   257, 24053,\n          5496,    13,  3260,   257,  1178,  2745,    11,   339,  2067,   284,\n          1254,   881,  1365,    13]], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Generate text\nwith torch.no_grad():\n    output = model.generate(input_ids=input_ids, max_length=150, num_return_sequences=1)\n\n# Decode the generated output\noutput_text = tokenizer.decode(output[0], skip_special_tokens=True)\n\nprint(\"Generated Output Text:\", output_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:59:57.718958Z","iopub.status.idle":"2024-04-12T15:59:57.719347Z","shell.execute_reply.started":"2024-04-12T15:59:57.719159Z","shell.execute_reply":"2024-04-12T15:59:57.719175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"David Drops the Weight David noticed he had put on a lot of weight recently.He examined his habits to try and figure out the reason.He realized he'd been eating too much fast food lately.He stopped going to burger places and started a vegetarian diet.After a few weeks, he started to feel much better.\n\nDavid Drops the Weight David noticed he had put on a lot of weight recently.He examined his habits to try and figure out the reason.He realized he'd been eating too much fast food lately.He stopped going to burger places and started a vegetarian diet.After a few weeks, he started to feel much better.","metadata":{}}]}