{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11384,"sourceType":"modelInstanceVersion","modelInstanceId":6216},{"sourceId":26140,"sourceType":"modelInstanceVersion","modelInstanceId":22003}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Prompt Engineering","metadata":{}},{"cell_type":"code","source":"# Setup the environment\n#!pip install --upgrade huggingface_hub transformers\n#!pip install bitsandbytes\n#from huggingface_hub import login\n#from kaggle_secrets import UserSecretsClient\n#access_token_read = UserSecretsClient().get_secret(\"HUGGINGFACE_TOKEN\")\n#login(token = access_token_read)\n#!pip install git+https://github.com/huggingface/transformers -U\n#!pip install accelerate\n#!pip install -i https://pypi.org/simple/ bitsandbytes","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-04-10T16:02:08.976602Z","iopub.execute_input":"2024-04-10T16:02:08.977005Z","iopub.status.idle":"2024-04-10T16:02:08.981831Z","shell.execute_reply.started":"2024-04-10T16:02:08.976971Z","shell.execute_reply":"2024-04-10T16:02:08.980727Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import torch, os\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n# Work around a bug in the version of PyTorch and GPU hardware curretnly on Kaggle. On other hardware, removing these lines may lead to a speed-up.\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\n# Load the model\nUSE_INSTRUCTION_TUNED = True # we'll switch this to True partway through the lab\nif USE_INSTRUCTION_TUNED:\n    model_name = '/kaggle/input/gemma/transformers/1.1-2b-it/1'\n    if not os.path.exists(model_name):\n        print(\"Warning: loading model weights from the Internet. This might take a bit of extra time.\")\n        model_name = \"google/gemma-1.1-2b-it\"\nelse:\n    model_name = \"/kaggle/input/gemma/transformers/2b/2\"\n    if not os.path.exists(model_name):\n        print(\"Warning: loading model weights from the Internet. This might take a bit of extra time.\")\n        model_name = \"google/gemma-2b\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map='auto',\n    torch_dtype=torch.bfloat16)\nstreamer = TextStreamer(tokenizer)\n# Silence a warning.\ntokenizer.decode([tokenizer.eos_token_id]);","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-04-10T16:02:08.983567Z","iopub.execute_input":"2024-04-10T16:02:08.983879Z","iopub.status.idle":"2024-04-10T16:02:12.508549Z","shell.execute_reply.started":"2024-04-10T16:02:08.983853Z","shell.execute_reply":"2024-04-10T16:02:12.507808Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50ace33c3b78426794c35139e8f592c1"}},"metadata":{}}]},{"cell_type":"code","source":"# Check where the whole model is loaded and what data type it's using.\nmodel.device, model.dtype","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:02:12.509651Z","iopub.execute_input":"2024-04-10T16:02:12.509962Z","iopub.status.idle":"2024-04-10T16:02:12.515573Z","shell.execute_reply.started":"2024-04-10T16:02:12.509936Z","shell.execute_reply":"2024-04-10T16:02:12.514655Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(device(type='cuda', index=0), torch.bfloat16)"},"metadata":{}}]},{"cell_type":"code","source":"# Check where parameters are loaded. If this is anything other than {'': 0}\n# then probably some parts of the model got offloaded onto CPU and so will run slow.\nmodel.hf_device_map","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:02:12.516741Z","iopub.execute_input":"2024-04-10T16:02:12.517358Z","iopub.status.idle":"2024-04-10T16:02:12.527016Z","shell.execute_reply.started":"2024-04-10T16:02:12.517322Z","shell.execute_reply":"2024-04-10T16:02:12.526173Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'': 0}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Warm-Up","metadata":{}},{"cell_type":"code","source":"%%time\ndoc = '''The capital of Michigan is Lansing.\nThe capital of England is London.\nThe capital of France is\n'''\nmodel_out = model.generate(\n    **tokenizer(doc, return_tensors='pt').to(model.device),\n    max_new_tokens=128,\n    do_sample=False,\n    streamer=streamer)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:02:12.528967Z","iopub.execute_input":"2024-04-10T16:02:12.529231Z","iopub.status.idle":"2024-04-10T16:02:13.992565Z","shell.execute_reply.started":"2024-04-10T16:02:12.529209Z","shell.execute_reply":"2024-04-10T16:02:13.991743Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"<bos>The capital of Michigan is Lansing.\nThe capital of England is London.\nThe capital of France is\na) Paris\nb) Lyon\nc) Marseille\nd) Bordeaux\n\nThe answer is a) Paris.\n\nThe capital of France is Paris. It is the political, economic, and cultural center of France.<eos>\nCPU times: user 1.45 s, sys: 8.81 ms, total: 1.46 s\nWall time: 1.45 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Chat Templating","metadata":{}},{"cell_type":"code","source":"role = \"\"\"You are a programmer.\"\"\"\ntask = \"\"\"Explain the options for TripletMarginLoss in PyTorch.\"\"\"\ncontext = docstrings['CrossEntropyLoss']\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": f\"{role}\\n\\n{task}\\n\\nAnswer using the following context:\\n{context}\",\n    },\n ]\ntokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n#print(tokenizer.batch_decode(tokenized_chat)[0])\n\noutputs = model.generate(tokenized_chat, max_new_tokens=128, do_sample=False, streamer=streamer)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:02:13.993611Z","iopub.execute_input":"2024-04-10T16:02:13.993911Z","iopub.status.idle":"2024-04-10T16:02:19.713012Z","shell.execute_reply.started":"2024-04-10T16:02:13.993887Z","shell.execute_reply":"2024-04-10T16:02:19.712232Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"<bos><start_of_turn>user\nYou are a programmer.\n\nExplain the options for TripletMarginLoss in PyTorch.\n\nAnswer using the following context:\nThis criterion computes the cross entropy loss between input logits\nand target.\n\nIt is useful when training a classification problem with `C` classes.\nIf provided, the optional argument :attr:`weight` should be a 1D `Tensor`\nassigning weight to each of the classes.\nThis is particularly useful when you have an unbalanced training set.\n\nThe `input` is expected to contain the unnormalized logits for each class (which do `not` need\nto be positive or sum to 1, in general).\n`input` has to be a Tensor of size :math:`(C)` for unbatched input,\n:math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` for the\n`K`-dimensional case. The last being useful for higher dimension inputs, such\nas computing cross entropy loss per-pixel for 2D images.\n\nThe `target` that this criterion expects should contain either:\n\n- Class indices in the range :math:`[0, C)` where :math:`C` is the number of classes; if\n  `ignore_index` is specified, this loss also accepts this class index (this index\n  may not necessarily be in the class range). The unreduced (i.e. with :attr:`reduction`\n  set to ``'none'``) loss for this case can be described as:\n\n  .. math::\n      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n      l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n      \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n\n  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n\n  .. math::\n      \\ell(x, y) = \\begin{cases}\n          \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n} \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}} l_n, &\n           \\text{if reduction} = \\text{`mean';}\\\\\n            \\sum_{n=1}^N l_n,  &\n            \\text{if reduction} = \\text{`sum'.}\n        \\end{cases}\n\n  Note that this case is equivalent to applying :class:`~torch.nn.LogSoftmax`\n  on an input, followed by :class:`~torch.nn.NLLLoss`.\n\n- Probabilities for each class; useful when labels beyond a single class per minibatch item\n  are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with\n  :attr:`reduction` set to ``'none'``) loss for this case can be described as:\n\n  .. math::\n      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n      l_n = - \\sum_{c=1}^C w_c \\log \\frac{\\exp(x_{n,c})}{\\sum_{i=1}^C \\exp(x_{n,i})} y_{n,c}\n\n  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n\n  .. math::\n      \\ell(x, y) = \\begin{cases}\n          \\frac{\\sum_{n=1}^N l_n}{N}, &\n           \\text{if reduction} = \\text{`mean';}\\\\\n            \\sum_{n=1}^N l_n,  &\n            \\text{if reduction} = \\text{`sum'.}\n        \\end{cases}\n\n.. note::\n    The performance of this criterion is generally better when `target` contains class\n    indices, as this allows for optimized computation. Consider providing `target` as\n    class probabilities only when a single class label per minibatch item is too restrictive.\n\nArgs:\n    weight (Tensor, optional): a manual rescaling weight given to each class.\n        If given, has to be a Tensor of size `C`\n    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n        the losses are averaged over each loss element in the batch. Note that for\n        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n        when :attr:`reduce` is ``False``. Default: ``True``\n    ignore_index (int, optional): Specifies a target value that is ignored\n        and does not contribute to the input gradient. When :attr:`size_average` is\n        ``True``, the loss is averaged over non-ignored targets. Note that\n        :attr:`ignore_index` is only applicable when the target contains class indices.\n    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n        losses are averaged or summed over observations for each minibatch depending\n        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n        batch element instead and ignores :attr:`size_average`. Default: ``True``\n    reduction (str, optional): Specifies the reduction to apply to the output:\n        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n        be applied, ``'mean'``: the weighted mean of the output is taken,\n        ``'sum'``: the output will be summed. Note: :attr:`size_average`\n        and :attr:`reduce` are in the process of being deprecated, and in\n        the meantime, specifying either of those two args will override\n        :attr:`reduction`. Default: ``'mean'``\n    label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n        of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n        become a mixture of the original ground truth and a uniform distribution as described in\n        `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n\nShape:\n    - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n      in the case of `K`-dimensional loss.\n    - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with\n      :math:`K \\geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.\n      If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.\n    - Output: If reduction is 'none', shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n      in the case of K-dimensional loss, depending on the shape of the input. Otherwise, scalar.\n\n\n    where:\n\n    .. math::\n        \\begin{aligned}\n            C ={} & \\text{number of classes} \\\\\n            N ={} & \\text{batch size} \\\\\n        \\end{aligned}\n\nExamples::\n\n    >>> # Example of target with class indices\n    >>> loss = nn.CrossEntropyLoss()\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> target = torch.empty(3, dtype=torch.long).random_(5)\n    >>> output = loss(input, target)\n    >>> output.backward()\n    >>>\n    >>> # Example of target with class probabilities\n    >>> input = torch.randn(3, 5, requires_grad=True)\n    >>> target = torch.randn(3, 5).softmax(dim=1)\n    >>> output = loss(input, target)\n    >>> output.backward()<end_of_turn>\n<start_of_turn>model\n**TripletMarginLoss** is a cross entropy loss function that computes the cross entropy between input logits and target.\n\n**Options:**\n\n**weight:**\n- A manual rescaling weight given to each class.\n- Required if provided, must be a Tensor of size `C`.\n\n**size_average:**\n- Deprecated. By default, losses are averaged over each loss element in the batch.\n- Ignored when `reduce` is `False`.\n\n**ignore_index:**\n- Specifies a target value that is ignored and does not contribute to the input gradient.\n- Applicable when `size_average` is\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Retrieval-Augmented Generation","metadata":{}},{"cell_type":"code","source":"import inspect\ndocstrings = {}\nfor name, obj in inspect.getmembers(torch.nn):\n    if inspect.isfunction(obj) or inspect.isclass(obj):\n        docstrings[name] = inspect.getdoc(obj)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:02:19.714160Z","iopub.execute_input":"2024-04-10T16:02:19.714440Z","iopub.status.idle":"2024-04-10T16:02:19.726926Z","shell.execute_reply.started":"2024-04-10T16:02:19.714416Z","shell.execute_reply":"2024-04-10T16:02:19.726074Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"docstrings.keys()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:02:19.728377Z","iopub.execute_input":"2024-04-10T16:02:19.728713Z","iopub.status.idle":"2024-04-10T16:02:19.739985Z","shell.execute_reply.started":"2024-04-10T16:02:19.728682Z","shell.execute_reply":"2024-04-10T16:02:19.739102Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"dict_keys(['AdaptiveAvgPool1d', 'AdaptiveAvgPool2d', 'AdaptiveAvgPool3d', 'AdaptiveLogSoftmaxWithLoss', 'AdaptiveMaxPool1d', 'AdaptiveMaxPool2d', 'AdaptiveMaxPool3d', 'AlphaDropout', 'AvgPool1d', 'AvgPool2d', 'AvgPool3d', 'BCELoss', 'BCEWithLogitsLoss', 'BatchNorm1d', 'BatchNorm2d', 'BatchNorm3d', 'Bilinear', 'CELU', 'CTCLoss', 'ChannelShuffle', 'CircularPad1d', 'CircularPad2d', 'CircularPad3d', 'ConstantPad1d', 'ConstantPad2d', 'ConstantPad3d', 'Container', 'Conv1d', 'Conv2d', 'Conv3d', 'ConvTranspose1d', 'ConvTranspose2d', 'ConvTranspose3d', 'CosineEmbeddingLoss', 'CosineSimilarity', 'CrossEntropyLoss', 'CrossMapLRN2d', 'DataParallel', 'Dropout', 'Dropout1d', 'Dropout2d', 'Dropout3d', 'ELU', 'Embedding', 'EmbeddingBag', 'FeatureAlphaDropout', 'Flatten', 'Fold', 'FractionalMaxPool2d', 'FractionalMaxPool3d', 'GELU', 'GLU', 'GRU', 'GRUCell', 'GaussianNLLLoss', 'GroupNorm', 'Hardshrink', 'Hardsigmoid', 'Hardswish', 'Hardtanh', 'HingeEmbeddingLoss', 'HuberLoss', 'Identity', 'InstanceNorm1d', 'InstanceNorm2d', 'InstanceNorm3d', 'KLDivLoss', 'L1Loss', 'LPPool1d', 'LPPool2d', 'LSTM', 'LSTMCell', 'LayerNorm', 'LazyBatchNorm1d', 'LazyBatchNorm2d', 'LazyBatchNorm3d', 'LazyConv1d', 'LazyConv2d', 'LazyConv3d', 'LazyConvTranspose1d', 'LazyConvTranspose2d', 'LazyConvTranspose3d', 'LazyInstanceNorm1d', 'LazyInstanceNorm2d', 'LazyInstanceNorm3d', 'LazyLinear', 'LeakyReLU', 'Linear', 'LocalResponseNorm', 'LogSigmoid', 'LogSoftmax', 'MSELoss', 'MarginRankingLoss', 'MaxPool1d', 'MaxPool2d', 'MaxPool3d', 'MaxUnpool1d', 'MaxUnpool2d', 'MaxUnpool3d', 'Mish', 'Module', 'ModuleDict', 'ModuleList', 'MultiLabelMarginLoss', 'MultiLabelSoftMarginLoss', 'MultiMarginLoss', 'MultiheadAttention', 'NLLLoss', 'NLLLoss2d', 'PReLU', 'PairwiseDistance', 'Parameter', 'ParameterDict', 'ParameterList', 'PixelShuffle', 'PixelUnshuffle', 'PoissonNLLLoss', 'RNN', 'RNNBase', 'RNNCell', 'RNNCellBase', 'RReLU', 'ReLU', 'ReLU6', 'ReflectionPad1d', 'ReflectionPad2d', 'ReflectionPad3d', 'ReplicationPad1d', 'ReplicationPad2d', 'ReplicationPad3d', 'SELU', 'Sequential', 'SiLU', 'Sigmoid', 'SmoothL1Loss', 'SoftMarginLoss', 'Softmax', 'Softmax2d', 'Softmin', 'Softplus', 'Softshrink', 'Softsign', 'SyncBatchNorm', 'Tanh', 'Tanhshrink', 'Threshold', 'Transformer', 'TransformerDecoder', 'TransformerDecoderLayer', 'TransformerEncoder', 'TransformerEncoderLayer', 'TripletMarginLoss', 'TripletMarginWithDistanceLoss', 'Unflatten', 'Unfold', 'UninitializedBuffer', 'UninitializedParameter', 'Upsample', 'UpsamplingBilinear2d', 'UpsamplingNearest2d', 'ZeroPad1d', 'ZeroPad2d', 'ZeroPad3d', 'factory_kwargs'])"},"metadata":{}}]}]}