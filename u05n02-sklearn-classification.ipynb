{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Classification in `scikit-learn`\n\nGoals:\n\n* Practice with the `fit` and `predict` interface of sklearn models\n* Compare and contrast regression and classification as machine learning tasks","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"markdown","source":"Much of this setup is the same as the regression notebook.","metadata":{}},{"cell_type":"markdown","source":"Let's import necessary modules: Pandas and NumPy for data wrangling, Matplotlib for plotting, and some sklearn models.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, log_loss, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:12.446984Z","iopub.execute_input":"2024-02-23T16:03:12.447720Z","iopub.status.idle":"2024-02-23T16:03:16.142468Z","shell.execute_reply.started":"2024-02-23T16:03:12.447672Z","shell.execute_reply":"2024-02-23T16:03:16.141096Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"We'll load the data. We're using a dataset of home sale prices from the Ames, Iowa assessor's database, described in [this paper](http://ww2.amstat.org/publications/jse/v19n3/decock.pdf).","metadata":{}},{"cell_type":"code","source":"ames = pd.read_csv('https://github.com/kcarnold/AmesHousing/blob/master/data/ames.csv.gz?raw=true', compression=\"gzip\")\names['price'] = ames[\"Sale_Price\"] / 100_000 # Make `price` be in units of $100k, to be easier to interpret.\names.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:16.145194Z","iopub.execute_input":"2024-02-23T16:03:16.146291Z","iopub.status.idle":"2024-02-23T16:03:16.955366Z","shell.execute_reply.started":"2024-02-23T16:03:16.146249Z","shell.execute_reply":"2024-02-23T16:03:16.953969Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                           MS_SubClass                 MS_Zoning  \\\n0  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n1  One_Story_1946_and_Newer_All_Styles  Residential_High_Density   \n2  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n3  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n4             Two_Story_1946_and_Newer   Residential_Low_Density   \n\n   Lot_Frontage  Lot_Area Street            Alley           Lot_Shape  \\\n0           141     31770   Pave  No_Alley_Access  Slightly_Irregular   \n1            80     11622   Pave  No_Alley_Access             Regular   \n2            81     14267   Pave  No_Alley_Access  Slightly_Irregular   \n3            93     11160   Pave  No_Alley_Access             Regular   \n4            74     13830   Pave  No_Alley_Access  Slightly_Irregular   \n\n  Land_Contour Utilities Lot_Config  ... Misc_Feature Misc_Val Mo_Sold  \\\n0          Lvl    AllPub     Corner  ...          NaN        0       5   \n1          Lvl    AllPub     Inside  ...          NaN        0       6   \n2          Lvl    AllPub     Corner  ...         Gar2    12500       6   \n3          Lvl    AllPub     Corner  ...          NaN        0       4   \n4          Lvl    AllPub     Inside  ...          NaN        0       3   \n\n  Year_Sold Sale_Type Sale_Condition Sale_Price  Longitude   Latitude  price  \n0      2010       WD          Normal     215000 -93.619754  42.054035  2.150  \n1      2010       WD          Normal     105000 -93.619756  42.053014  1.050  \n2      2010       WD          Normal     172000 -93.619387  42.052659  1.720  \n3      2010       WD          Normal     244000 -93.617320  42.051245  2.440  \n4      2010       WD          Normal     189900 -93.638933  42.060899  1.899  \n\n[5 rows x 82 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MS_SubClass</th>\n      <th>MS_Zoning</th>\n      <th>Lot_Frontage</th>\n      <th>Lot_Area</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>Lot_Shape</th>\n      <th>Land_Contour</th>\n      <th>Utilities</th>\n      <th>Lot_Config</th>\n      <th>...</th>\n      <th>Misc_Feature</th>\n      <th>Misc_Val</th>\n      <th>Mo_Sold</th>\n      <th>Year_Sold</th>\n      <th>Sale_Type</th>\n      <th>Sale_Condition</th>\n      <th>Sale_Price</th>\n      <th>Longitude</th>\n      <th>Latitude</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One_Story_1946_and_Newer_All_Styles</td>\n      <td>Residential_Low_Density</td>\n      <td>141</td>\n      <td>31770</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Slightly_Irregular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>215000</td>\n      <td>-93.619754</td>\n      <td>42.054035</td>\n      <td>2.150</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>One_Story_1946_and_Newer_All_Styles</td>\n      <td>Residential_High_Density</td>\n      <td>80</td>\n      <td>11622</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Regular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>105000</td>\n      <td>-93.619756</td>\n      <td>42.053014</td>\n      <td>1.050</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>One_Story_1946_and_Newer_All_Styles</td>\n      <td>Residential_Low_Density</td>\n      <td>81</td>\n      <td>14267</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Slightly_Irregular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>...</td>\n      <td>Gar2</td>\n      <td>12500</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>172000</td>\n      <td>-93.619387</td>\n      <td>42.052659</td>\n      <td>1.720</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>One_Story_1946_and_Newer_All_Styles</td>\n      <td>Residential_Low_Density</td>\n      <td>93</td>\n      <td>11160</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Regular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>244000</td>\n      <td>-93.617320</td>\n      <td>42.051245</td>\n      <td>2.440</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Two_Story_1946_and_Newer</td>\n      <td>Residential_Low_Density</td>\n      <td>74</td>\n      <td>13830</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Slightly_Irregular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>189900</td>\n      <td>-93.638933</td>\n      <td>42.060899</td>\n      <td>1.899</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 82 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We'll try to predict home price based on *location* (which the realtors assure us is the most important factor anyway). So we'll grab the Latitude and Longitude columns of the data. We'll call that input data `X`, by convention.","metadata":{}},{"cell_type":"code","source":"X = ames[['Longitude', 'Latitude']].values\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:16.957052Z","iopub.execute_input":"2024-02-23T16:03:16.958339Z","iopub.status.idle":"2024-02-23T16:03:16.967851Z","shell.execute_reply.started":"2024-02-23T16:03:16.958296Z","shell.execute_reply":"2024-02-23T16:03:16.966714Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(2930, 2)"},"metadata":{}}]},{"cell_type":"markdown","source":"We'll do something different for `y`; see below.","metadata":{}},{"cell_type":"markdown","source":"## Task","metadata":{}},{"cell_type":"markdown","source":"Notice that the distribution of sale prices is skewed.","metadata":{}},{"cell_type":"code","source":"plt.hist(ames.price);","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:16.971140Z","iopub.execute_input":"2024-02-23T16:03:16.971596Z","iopub.status.idle":"2024-02-23T16:03:17.262518Z","shell.execute_reply.started":"2024-02-23T16:03:16.971557Z","shell.execute_reply":"2024-02-23T16:03:17.261528Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"Skew can make regression hard because errors in the tails (in this case, the expensive houses) can dominate: mispredicting a million-dollar home by 1% is as bad as mispredicting a \\$100k home by 10%!\n\nOne way to resolve this is to transform the target variable to be more evenly distributed. (For example, a log transformation will make all percentage errors equally important.) Another way is to transform it into a *classification* problem, where we predict whether the home price is *low*, *medium*, or *high*. We'll skip lots of nuance here and just split the prices into 3 equal buckets.","metadata":{}},{"cell_type":"code","source":"# This is some Pandas trickery. Enjoy, those who dare venture here! Otherwise don't worry about it.\names['price_rank'] = ames.price.rank(pct=True)\names['price_bin'] = 0 + (ames.price_rank > 1/3) + (ames.price_rank > 2/3)\names.price_bin.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.263900Z","iopub.execute_input":"2024-02-23T16:03:17.264534Z","iopub.status.idle":"2024-02-23T16:03:17.290329Z","shell.execute_reply.started":"2024-02-23T16:03:17.264500Z","shell.execute_reply":"2024-02-23T16:03:17.289470Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"price_bin\n0    981\n1    980\n2    969\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"**Make a target `y` using the `price_bin` column of `ames`.**","metadata":{}},{"cell_type":"code","source":"y = ames['price_bin']","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:05:01.184819Z","iopub.execute_input":"2024-02-23T16:05:01.185205Z","iopub.status.idle":"2024-02-23T16:05:01.191690Z","shell.execute_reply.started":"2024-02-23T16:05:01.185175Z","shell.execute_reply":"2024-02-23T16:05:01.190239Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Split the data (`X` and `y`) into a training and validation set** using the same fraction and seed as the previous notebook.","metadata":{}},{"cell_type":"code","source":"# your code here\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.303537Z","iopub.status.idle":"2024-02-23T16:03:17.304132Z","shell.execute_reply.started":"2024-02-23T16:03:17.303851Z","shell.execute_reply":"2024-02-23T16:03:17.303876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We could use the plotting mechanism we used for regression in the previous notebook (try it, it does work), but it's a bit confusing because the model will be predicting 0, 1, or 2, while the data is in the original range. That would also omit one cool thing we gain by moving to a classifier: we get *probabilities*! You can interpret that as the model's *confidence* about a home price prediction. We could do this with regression too, but it's more complex; it comes for free with classification.\n\nHere we define the new plotting function; don't worry about how it works.","metadata":{}},{"cell_type":"code","source":"def plot_class_probs(clf):\n    lat_min = ames.Latitude.min()\n    lat_max = ames.Latitude.max()\n    lon_min = ames.Longitude.min()\n    lon_max = ames.Longitude.max()\n\n    xx, yy = np.meshgrid(np.linspace(lon_min, lon_max, 500), np.linspace(lat_min, lat_max, 500))\n    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n\n    n_classes = Z.shape[1]\n    fig, axs = plt.subplots(ncols=n_classes, figsize=(16, 6), sharey=True)\n    for i, ax in enumerate(axs):\n        contour = ax.contourf(xx, yy, Z[:, i].reshape(xx.shape), alpha=.5, cmap=plt.cm.RdBu_r)#, vmin=0., vmax=1.)\n        ax.scatter(ames['Longitude'], ames['Latitude'], s=.5, color='k')\n        ax.set(title=f\"Class {i} probabilities\", xlabel=\"Longitude\")\n    axs[0].set(ylabel=\"Latitude\")\n    fig.colorbar(contour, ax=ax, fraction=.05)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.306110Z","iopub.status.idle":"2024-02-23T16:03:17.306697Z","shell.execute_reply.started":"2024-02-23T16:03:17.306394Z","shell.execute_reply":"2024-02-23T16:03:17.306418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Part A: Logistic Regression\n\nLogistic regression is a classification algorithm, despite the name! It's the classifier version of linear regression.\n\n**Fit a logistic regression model (call it `logreg`) to our training set (`X_train` and `y_train`).**","metadata":{}},{"cell_type":"code","source":"logreg = ...","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.308020Z","iopub.status.idle":"2024-02-23T16:03:17.308563Z","shell.execute_reply.started":"2024-02-23T16:03:17.308286Z","shell.execute_reply":"2024-02-23T16:03:17.308308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's plot the class probabilities. Notice the range of values (in the color bar). What do you think the model will classify homes in the northwest (top left) corner as?","metadata":{}},{"cell_type":"code","source":"plot_class_probs(logreg)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.311452Z","iopub.status.idle":"2024-02-23T16:03:17.311904Z","shell.execute_reply.started":"2024-02-23T16:03:17.311695Z","shell.execute_reply":"2024-02-23T16:03:17.311715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compute the accuracy and categorical cross-entropy loss** on the validation set.\n\nYou can use `accuracy_score` and `log_loss`. You'll need to use `predict_proba` for one of these (which one?) to ask the classifier to tell you its probabilities, not just its best guess.\n\nNote: *categorical cross-entropy loss* is also known as *log loss*; think about why.","metadata":{}},{"cell_type":"code","source":"def summarize_classifier(clf, X_valid, y_valid):\n    print(\"Accuracy: {:.3f}\".format(accuracy_score(y_valid, ...)))\n    print(\"Log loss: {:.3f}\".format(log_loss(y_valid, ...)))\nsummarize_classifier(logreg, X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.314496Z","iopub.status.idle":"2024-02-23T16:03:17.314924Z","shell.execute_reply.started":"2024-02-23T16:03:17.314725Z","shell.execute_reply":"2024-02-23T16:03:17.314742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Part B: Decision tree classifier","metadata":{}},{"cell_type":"markdown","source":"**Fit a decision tree classifier (call it `dtree_clf`) to the training set**. Use the default hyperparameters.","metadata":{}},{"cell_type":"code","source":"dtree_clf = DecisionTreeClassifier()...","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.316398Z","iopub.status.idle":"2024-02-23T16:03:17.317367Z","shell.execute_reply.started":"2024-02-23T16:03:17.317061Z","shell.execute_reply":"2024-02-23T16:03:17.317087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's plot the probabilities for this classifier.","metadata":{}},{"cell_type":"code","source":"plot_class_probs(dtree_clf)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.318938Z","iopub.status.idle":"2024-02-23T16:03:17.320013Z","shell.execute_reply.started":"2024-02-23T16:03:17.319758Z","shell.execute_reply":"2024-02-23T16:03:17.319789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compute the accuracy and cross-entropy loss**. Be careful to use the correct classifier each time!","metadata":{}},{"cell_type":"code","source":"summarize_classifier(..., X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.321539Z","iopub.status.idle":"2024-02-23T16:03:17.322012Z","shell.execute_reply.started":"2024-02-23T16:03:17.321820Z","shell.execute_reply":"2024-02-23T16:03:17.321838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Part C: Random Forest\n\nA random forest consists of many different decision trees, but:\n\n1. Each tree only gets a random subset of the training data\n2. Each time the tree splits, it only gets to look at a random subset of the features. (We're only using two features overall, so this doesn't make much difference.)\n\nTo make a decision, it averages the decisions of each tree. (This means it's an \"ensemble\" method.)\n\nThe net effect is that an RF can fit the data well (since each tree is a pretty good predictor) but it tends not to *overfit* because it averages the predictions of trees trained on different subsets of data.\n\nLet's try it.","metadata":{}},{"cell_type":"markdown","source":"**Fit a random forest classifier to the training set.**","metadata":{}},{"cell_type":"code","source":"rf_clf = ...","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.324009Z","iopub.status.idle":"2024-02-23T16:03:17.324547Z","shell.execute_reply.started":"2024-02-23T16:03:17.324269Z","shell.execute_reply":"2024-02-23T16:03:17.324291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_class_probs(rf_clf)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.326459Z","iopub.status.idle":"2024-02-23T16:03:17.327013Z","shell.execute_reply.started":"2024-02-23T16:03:17.326735Z","shell.execute_reply":"2024-02-23T16:03:17.326768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compute the accuracy and cross-entropy loss**. Be careful to use the correct classifier each time!","metadata":{}},{"cell_type":"code","source":"# your code here","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.328983Z","iopub.status.idle":"2024-02-23T16:03:17.329500Z","shell.execute_reply.started":"2024-02-23T16:03:17.329237Z","shell.execute_reply":"2024-02-23T16:03:17.329259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analysis","metadata":{}},{"cell_type":"markdown","source":"**How does the accuracy compare between the three classifiers?**","metadata":{}},{"cell_type":"markdown","source":"*your narrative answer here*","metadata":{}},{"cell_type":"markdown","source":"**How does the cross-entropy loss compare between the three classifiers?** Why is the ranking different for this loss compared with accuracy? Look at the actual values. Hint:","metadata":{}},{"cell_type":"code","source":"-np.log(1/3)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T16:03:17.331399Z","iopub.status.idle":"2024-02-23T16:03:17.331967Z","shell.execute_reply.started":"2024-02-23T16:03:17.331688Z","shell.execute_reply":"2024-02-23T16:03:17.331711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*your narrative answer here*","metadata":{}},{"cell_type":"markdown","source":"**Describe, qualitatively, the shapes that each classifier makes in its class probability plots.** Explain how the accuracy and cross-entropy numbers make sense in light of these plots.","metadata":{}},{"cell_type":"markdown","source":"*your narrative answer here*","metadata":{}},{"cell_type":"markdown","source":"**Which of these classifiers *overfit*? Which ones *underfit*?**","metadata":{}},{"cell_type":"markdown","source":"*your narrative answer here*","metadata":{}},{"cell_type":"markdown","source":"## Extension\n\n*optional*\n\n1. Compute the loss on the *training* set for each of these classifiers. Can that help you tell whether your classifier overfit or not?\n2. Try using more features in the dataset. How well can you classify? Be careful about *categorical* features.","metadata":{}}]}